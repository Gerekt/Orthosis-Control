{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobileNetTraining_ControlSystem.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Library imports and parameters"
      ],
      "metadata": {
        "id": "mJuV8N2cGJ8n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ND-rqsMFEQ02"
      },
      "outputs": [],
      "source": [
        "import time, os, sys, shutil, pathlib, random, math, csv\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sc\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy.io.wavfile import write\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import display\n",
        "from IPython.display import Audio\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "seed = 69 #Sets the randomisation seed, in order to get the same RNG each session\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "\n",
        "#Parameters\n",
        "gdrive_path = Path(\"/content/gdrive/MyDrive/Datasets\") / (\"MSWC_dataset_wavs/MSWC_keywords_wavs.zip\") #Path to the dataset with wav files consisting of the selected keywords(located in googleDrive)\n",
        "modelSavePath = Path(\"/content/gdrive/MyDrive/Saved_models/\") #Path where to save the trained model, tfLite version will be saved in a new folder at this path\n",
        "custom_dataset_path = Path(\"/content/gdrive/MyDrive/Datasets/Real-life_Verification/\") #Path where custom wav files are located, used at the end for more testing of the trained model. Files need to be 16kHz .WAV files\n",
        "\n",
        "modelType = \"simpleCNN\" #CNN architecture that will be used: \"simpleCNN\", \"mobileNetV1\", \"mobileNetV2\" or \"mobileNetV3\" or \"efficientNet\". Only simpleCNN works reliably\n",
        "alphaMobileNet = 0.7 #MobileNet architecture widht/complexity setting (Value from 0.1 to 1.0)\n",
        "dropoutMobileNet = 0.005 #MobileNetV1 dropout setting (0.001 default)\n",
        "datasetType = \"MSWC\" #Dataset that will be used: \"MSWC\" (Multilingual Spoken Word Corpus) or \"GSC\" (Google Speech Commands)\n",
        "\n",
        "#Data augmentation parameters\n",
        "data_augmentation_bool = True #Whether or not data augmentation will be performed on the TRAIN set\n",
        "augmentation_chance = 0.25 #Percentage of files that are augmented\n",
        "\n",
        "#Files can have the following augmentations: only time-shifted, only noise added, shifted and noise added. \n",
        "shift_audio_bool = True\n",
        "shift_percentage = 0.5  #Percentage of the to be augmented files that are shifted in time\n",
        "add_noise_bool = True\n",
        "noise_percentage = 0.3  #Percentage of the to be augmented files that have noise added\n",
        "desired_snr = 10 #Deisred SNR(Signal to Noise Ratio) for the noise to be added\n",
        "normalize_spectrogram_bool = False #Whetether or not to normalize the output spectrogram to -1 and +1(Needed for MobileNet)\n",
        "\n",
        "\n",
        "#Spectrogram parameters\n",
        "make_3D_bool = False #Whether or not to change the dimensions of the spectrogram to: W x H x 3, instead of: W x H x 1. \n",
        "sampleRate = 16000 #Sample rate of the audio files\n",
        "sampleSegment = 256 #Window size of spectrogram in samples, 256 default (!!Note: The output shape of the spectrogram is hard coded, this needs to be manually changed in get_spectrogram() when changing segment or hop sizes!!)\n",
        "sampleHop = 128 #Hoplength of spectrogram in samples, 128 default. Can't be < sampleSegment\n",
        "nfftSize = sampleSegment #Size of the NFFT transformation, default is the same as sampleSegment(256). Needs to be >= sampleSegment!\n",
        "windowSpec = sc.signal.windows.hann(sampleSegment) #Spectrogram window that will be used\n",
        "\n",
        "#Training parameters\n",
        "EPOCHS = 60 #Amount of training cycles (Training may end earlier due to early stopping metrics)\n",
        "batch_size = 64 #Amount of examples that are included in each batch that is used for training, 64 default"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if certain Google Colab settings have been initialized(High-ram and GPU)\n",
        "\n",
        "High-ram not needed, but GPU recommended due to massively reduced training time"
      ],
      "metadata": {
        "id": "e-nUVRLso2Ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "\n",
        "ram_gb = virtual_memory().total / 1e9 #Checks if the high RAM-runtime is enabled inside of Google Colab\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM'.format(ram_gb))\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime, go to Runtime -> Change runtime type -> Runtime shape -> High-Ram')\n",
        "  print(\"High ram is not strictly neccesary\")\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "\n",
        "if device_name != '/device:GPU:0': #Checks if a GPU is enabled or used in Google Colab\n",
        "  raise SystemError('GPU device not found(Training will be slower), to enable: go to Runtime -> Change runtime type -> Hardware accelerator: GPU')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT_y283QsdP1",
        "outputId": "e05a9226-24be-4519-a4eb-43530990e173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/device:GPU:0\n",
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "You are using a high-RAM runtime!\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive and download the dataset\n"
      ],
      "metadata": {
        "id": "z8jzTSQcWU79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#shutil.rmtree(\"/content/dataset\")\n",
        "try: \n",
        "  drive.mount('/content/gdrive', force_remount=False) #Initialize the Google Drive\n",
        "  print(\"Google Drive succes!\")\n",
        "except:\n",
        "  print(\"Error, gdrive mount fault\")\n",
        "\n",
        "datasetPath = Path(\"/content/dataset\")\n",
        "if os.path.exists(datasetPath) != True: os.mkdir(datasetPath) #Make path if it doesn't exist\n",
        "\n",
        "try:\n",
        "  shutil.unpack_archive(gdrive_path, datasetPath, \"zip\") #Unpack the dataset .ZIP from google drive into the local machine\n",
        "  print(\"Dataset unpacked from Gdrive and placed in: \", datasetPath)\n",
        "except:\n",
        "  print(\"Could not unpack dataset\")"
      ],
      "metadata": {
        "id": "5wb6pquxWUZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970f90e8-0b7b-4ee7-ea80-c2dcae469e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Google Drive succes!\n",
            "Dataset unpacked from Gdrive and placed in:  /content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function decleration\n",
        "\n",
        "Declaration of several helper functions"
      ],
      "metadata": {
        "id": "FAk78t6OXaGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_filenames(commands, set): #Loads the filePaths of a SET\n",
        "  filenames = []\n",
        "  for item in commands:\n",
        "    filenames = filenames + tf.io.gfile.glob(str(datasetPath / set / item) + \"/*\") #Load all the paths and filenames that are present in the splits and commands\n",
        "  print(\"Number of paths that were found: \", len(filenames))\n",
        "  shuffled_filnames = tf.random.shuffle(filenames) #Shuffle list in order to remove paterns\n",
        "  return shuffled_filnames\n",
        "\n",
        "def decode_audio(encoded_audio): #Decodes a wav file to the raw audio waveform, also makes sure that it is the right shape and size(16000 samples)\n",
        "  decoded_audio, _ = tf.audio.decode_wav(contents=encoded_audio) #Decodes the .WAV and normalizes to -1.0 and +1.0\n",
        "  decoded_audio = tf.squeeze(decoded_audio, axis=-1) #Remove stereo channel, make mono\n",
        "  #Data normalization\n",
        "  decoded_audio = decoded_audio[:sampleRate] #Remove excess samples if present, only 1 second should be present\n",
        "  zero_padding = tf.zeros([sampleRate] - tf.shape(decoded_audio), dtype=tf.float32) #Make a zero filled array to pad the loaded audio if too few samples are present\n",
        "  decoded_audio = tf.cast(decoded_audio, dtype=tf.float32) #Make sure that the audio is a 32-bit float\n",
        "  equal_length_audio = tf.concat([decoded_audio, zero_padding], 0) #Pad audio with additional samples if shorter than 1 second of audio\n",
        "  return equal_length_audio\n",
        "\n",
        "def wav_preProcessing(filePath): #Preprocesses a path to a file to a spectrogram and label_id\n",
        "  label, set = get_label_from_path(filePath) #Get the label and set assasioated with the filePath\n",
        "  label_id = get_label_id(label) #Transform label string to a index integer, since strings can't be used for training\n",
        "\n",
        "  audio_binary = tf.io.read_file(filePath) #Load and read the .WAV located at the filePath\n",
        "  waveform = decode_audio(audio_binary) #Decode the .WAV file to usable audio, also normalizes the audio\n",
        "\n",
        "  spectrogram = get_spectrogram(waveform) #Convert the audio to a spectrogram\n",
        "  return spectrogram, label_id\n",
        "\n",
        "def ds_preProcessing(set): #Preprocesses a set of files into a TF dataset object for training\n",
        "  allFiles = load_filenames(commands, set) #Load all audio files in the set\n",
        "  print(\"Amount of files in the set: \", len(allFiles))\n",
        "  if set == \"TRAIN\" and data_augmentation_bool == True: #Only augment training data\n",
        "    data_augmentation(allFiles) #Performs data augmentation and saves augmented files as WAV files\n",
        "    allFiles = load_filenames(commands, set) #Reload all files in order to include the new augmented samples(Inefficient but far easier this way when using tf.datasets)\n",
        "\n",
        "  files_ds = tf.data.Dataset.from_tensor_slices(allFiles) #Make dataset with only the filePaths of all the WAVs\n",
        "  output_ds = files_ds.map(\n",
        "      map_func=(lambda file_path: wav_preProcessing(file_path)), #Preprocess into a new dataset of spectrograms and labels\n",
        "      num_parallel_calls=AUTOTUNE)\n",
        "  \n",
        "  if normalize_spectrogram_bool == True: #Normalize the dataset into a new one. Normalization will make the values of the spectrogram fit between -1.0 and +1.0\n",
        "    normalized_ds = output_ds.map(\n",
        "      map_func=(lambda spectrogram, label: normalize_spectrogram(spectrogram, label)), \n",
        "      num_parallel_calls=AUTOTUNE)\n",
        "    return normalized_ds\n",
        "  else: return output_ds  "
      ],
      "metadata": {
        "id": "rYUHPNjZTWR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get functions"
      ],
      "metadata": {
        "id": "GAah02IfWoXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_commands(ds_path): #Get all the available commands\n",
        "  commands_dirs = sorted(os.listdir((ds_path / \"TRAIN\")))\n",
        "  return commands_dirs\n",
        "\n",
        "def get_label_from_path(filePath): #Gets the label of a wav file based on it's path\n",
        "  splitPath = tf.strings.split(filePath, os.path.sep)\n",
        "  label = splitPath[-2] #Second last word includes the class of the path, last word is the filename of the WAV\n",
        "  set = splitPath[-3]\n",
        "  return label, set\n",
        "\n",
        "def get_label_id(label): #Gets the label_id, I.E a integer value of the label\n",
        "  label_id = tf.argmax(label == commands)\n",
        "  return label_id\n",
        "\n",
        "def get_waveform_from_path(filePath): #Gets the raw audio of a wav path\n",
        "  audio_binary = tf.io.read_file(filePath)\n",
        "  waveform = decode_audio(audio_binary)\n",
        "  return waveform\n",
        "\n",
        "def get_spectrogram(audio): #Converts audio to a spectrogram\n",
        "  spectrogram = tf.py_function(__spectrogram__, [audio], tf.float32) #Tensorflow Py function for eager execution while being run by a dataset object, needed as the function otherwise crashes\n",
        "  if make_3D_bool == True:\n",
        "    spectrogram_3D = tf.stack([spectrogram, spectrogram, spectrogram], axis=-1) #Make a 3 dimensional image of the spectrogram if desired\n",
        "    spectrogram_3D.set_shape((129 , 124, 1)) #Manually set the shape of the spectrogram, as the shape is not set due to the use of py_function \n",
        "    return spectrogram_3D\n",
        "  else:\n",
        "    spectrogram = tf.expand_dims(spectrogram, -1) #Add dimension to spectrogram in order to make it (X x Y x 1), instead of (X x Y)\n",
        "    spectrogram.set_shape((129 , 124, 1)) #Manually set the shape, as the py_function doesn't allow for shape data to be transfered.\n",
        "  return spectrogram\n",
        "\n",
        "def __spectrogram__(audio): #Helper function of get_spectrogram()\n",
        "  _, _, spectrogram = sc.signal.spectrogram(audio, fs=sampleRate, nperseg=sampleSegment, noverlap=sampleHop, \n",
        "                                      nfft=nfftSize, mode=\"magnitude\", window=windowSpec)\n",
        "  return spectrogram\n",
        "\n",
        "def get_spectrogram_plot(spectrogram): #Plots a spectrogram picture\n",
        "  if len(spectrogram.shape) > 2:\n",
        "    assert len(spectrogram.shape) == 3 #Throws an error if the spectrogram dimension is larger than 3, as the spectrogram shape should be W x H x D\n",
        "    if spectrogram.shape[2] == 1: #If only the spectrogram is not 3D, meaning W x H x 1. Remove the last dimension to make it W x H\n",
        "      spectrogram = tf.squeeze(spectrogram, axis=-1)\n",
        "    elif spectrogram.shape[2] == 3: #If the spectrogram is 3D, meaning W x H x 3. Unstacks the tensor and gives W x H\n",
        "      spectrogram, _, _ = tf.unstack(spectrogram, axis=-1)\n",
        "    else: sys.exit(\"Error, invalid shape\")\n",
        "  plt.pcolormesh(spectrogram) #Plot spectrogram and set labels of axes\n",
        "  plt.ylabel(\"Frequency\")\n",
        "  plt.xlabel(\"Time\")\n",
        "  plt.show()\n",
        "  return\n",
        "\n",
        "def get_audio_source(audio): #Gets the audio as a playable source\n",
        "  display.display(display.Audio(audio, rate=16000))\n",
        "  return\n",
        "\n",
        "def get_audio_plot(audio, title=\"Raw wave \"): #Gets an plot of the audio waveform\n",
        "  fig = plt.figure(figsize=(14, 8))\n",
        "  plt.title(title)\n",
        "  plt.ylabel('Amplitude')\n",
        "  plt.plot(np.linspace(0, 1, len(audio)), audio)\n",
        "  plt.show()\n",
        "  return\n",
        "\n",
        "def get_model_name(): #Gets the next available model name\n",
        "  modelFiles = os.listdir(modelSavePath) #Get all the saved model names\n",
        "  newestModelVersion = 0\n",
        "  for index, modelFile in enumerate(modelFiles):\n",
        "    fileVersion = tf.strings.split(modelFile, \"_\")[0] #Extract only the model version\n",
        "    fileVersion = fileVersion.numpy().decode('utf-8') #Covert tensor to string\n",
        "    if fileVersion[0] == \"V\": #Only check for model versions, not other files or directories\n",
        "      fileVersion = float(fileVersion[1:]) #Covert to float and remove the V\n",
        "      if fileVersion > newestModelVersion: newestModelVersion = fileVersion #Save highest model version\n",
        "  modelVersion += 1 #Increment the model version by 1\n",
        "\n",
        "  currentTime = datetime.now() #Get current date\n",
        "  dateModel = currentTime.strftime(\"%d/%m/%Y\")\n",
        "  dateModel = dateModel.replace(\"/\", \"-\") #Replace backslashes with -, as it gives problems while making folders\n",
        "\n",
        "  usedKeywords = \"\"\n",
        "  for index, keyword in enumerate(commands): #Check for used keywords, saves keywords\n",
        "    if index == 0: usedKeywords = \"_\" + str(keyword)\n",
        "    else: usedKeywords = usedKeywords + \"-\" + str(keyword)\n",
        "\n",
        "  modelName = \"V\" + str(modelVersion) + \"_\" + modelType + \"_\" + datasetType + usedKeywords + \"_spectrogram_\" + dateModel #Construct modelName based on version type and other parameters\n",
        "  modelNameTFlite = \"V\" + str(modelVersion) + \"_TFlite_\" + modelType + \"_\" + datasetType + usedKeywords + \"_spectrogram_\" + dateModel\n",
        "  return modelName, modelNameTFlite\n",
        "\n",
        "def get_seconds(frame_number, frame_length=16000, hop_length=8000): #Gets the time in seconds, based on the window number\n",
        "  samples_amount = hop_length * (frame_number + (frame_length/hop_length)) \n",
        "  end_of_frame_seconds = samples_amount / frame_length\n",
        "  assert end_of_frame_seconds >= 1.0, \"Invalid frame number given, frame can't be 0\"\n",
        "  return end_of_frame_seconds"
      ],
      "metadata": {
        "id": "vyhB3YgIWo_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation functions"
      ],
      "metadata": {
        "id": "uxmVWJFxWV_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_for_silences(audio): #Checks if a audio file is mostly silent, if so it may be discarded\n",
        "\n",
        "  return silence_status\n",
        "\n",
        "def data_augmentation(filePathList): #Applies the data augmentation techniques to the training set\n",
        "  print(\"Data augmentation\", filePathList)\n",
        "  augmented_files_path = datasetPath / \"TRAIN\"\n",
        "  for index, filePath in enumerate(filePathList):\n",
        "    if random.random() < augmentation_chance: #Don't augment all files, but rather a percentage o files\n",
        "      audio_binary = tf.io.read_file(filePath)\n",
        "      waveform = decode_audio(audio_binary)\n",
        "\n",
        "      randomizer = random.random()\n",
        "      if randomizer < shift_percentage: #Chooses between: Shifting, adding noise, shifting and noise addition. Based on their percentages that are set in the parameters\n",
        "        waveform = shift_audio(waveform)\n",
        "      elif randomizer < (noise_percentage + shift_percentage):\n",
        "        waveform = add_noise_to_audio(waveform)\n",
        "      else:\n",
        "        waveform = shift_audio(waveform)\n",
        "        waveform = add_noise_to_audio(waveform)\n",
        "\n",
        "      word = tf.strings.split(filePath, os.path.sep)[4].numpy().decode('utf-8') #Save the new augmented sample as a new audio file(Easier to do this way)\n",
        "      augmented_filename = \"augmented_\" + word + str(index) + \".wav\"\n",
        "      augmented_path = augmented_files_path / word / augmented_filename\n",
        "\n",
        "      try:\n",
        "        waveform = tf.expand_dims(waveform, -1) #Add stereo channel, as it can't be saved without it\n",
        "        wav = tf.audio.encode_wav(waveform, sampleRate) #Encode the audio to a .WAV\n",
        "        tf.io.write_file(str(augmented_path), wav) #Save the .WAV\n",
        "      except:\n",
        "        print(\"Path, samplerate is:\", augmented_path, sampleRate)\n",
        "        print(\"Waveform shape is:\", waveform.shape)\n",
        "        print(\"Unable to save .WAV!\")\n",
        "  return\n",
        "\n",
        "def add_noise_to_audio(clean_audio): #Adds gaussian noise to the audio\n",
        "  signal_watts = clean_audio ** 2\n",
        "  signal_avg_watts = tf.math.reduce_mean(signal_watts)\n",
        "  signal_avg_db = 10 * tf.math.log(signal_avg_watts) #Calculate average signal energy\n",
        "\n",
        "  noise_avg_db = signal_avg_db - desired_snr\n",
        "  noise_avg_watts = 10 ** (noise_avg_db / 10)\n",
        "  mean_noise = 0\n",
        "  noise_volts = tf.random.normal(shape=[len(signal_watts)], stddev=tf.math.sqrt(noise_avg_watts), dtype=tf.float32) #Make guassian noise distribution\n",
        "\n",
        "  noised_audio = clean_audio + noise_volts #Add noise to audio\n",
        "  return noised_audio\n",
        "\n",
        "def shift_audio(audio): #Moves the audio in time direction via a circular window\n",
        "  if random.randrange(2) == 0: #Randomly chooses either a positive or negative shift\n",
        "    random_shift = random.uniform(-3,-0.2) #Pick a number of samples(*1000) between -3000 and -200 to shift the waveform with  \n",
        "  else:                                    #This was chosen as the audio should always be shifted some amount(in this case 0,0125 sec) as otherwise it will just result in a duplicate training sample\n",
        "    random_shift = random.uniform(0.2, 3)  #The other maximum, 3000 samples, was chosen as a larger number may cause the actual word itself to roll over to the end/beginning of the window\n",
        "\n",
        "  random_shift_samples = math.ceil(random_shift * 1000)\n",
        "  shifted_audio = tf.roll(audio, random_shift_samples, axis=0) #Moves the 1 second audio window with the random shift amount, rolls the excluded samples to the beginning/end\n",
        "  return shifted_audio\n",
        "\n",
        "def normalize_spectrogram(spectrogram, label): #Normalizes a spectrogram to values between -1.0 and +1.0\n",
        "  if normalize_spectrogram_bool != True or modelType == \"mobileNetV3\" : return spectrogram, label #Don't normalize when not desired or when mobileNetV3 is used, as the normalization is included in the architecture\n",
        "  elif modelType == \"mobileNetV1\": #Uses mobileNetV1 preprocessing\n",
        "    normalized_spectrogram = tf.keras.applications.mobilenet.preprocess_input(spectrogram)\n",
        "  elif modelType == \"mobileNetV2\": #Uses mobileNetV2 preprocessing\n",
        "    normalized_spectrogram = tf.keras.applications.mobilenet_v2.preprocess_input(spectrogram)\n",
        "  else: #Uses mobileNetV1 preprocessing for everything else\n",
        "    normalized_spectrogram = tf.keras.applications.mobilenet.preprocess_input(spectrogram)\n",
        "  return normalized_spectrogram, label #Returns normalizes spectrogram and same label"
      ],
      "metadata": {
        "id": "FNk3zjnuTZQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function verification\n",
        "Tests in order to verify functions above"
      ],
      "metadata": {
        "id": "3Q55eM02pSph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "commands = get_commands(datasetPath)\n",
        "allTestFiles = load_filenames(commands, \"DEV\")\n",
        "print(commands)\n",
        "for itteration, path in enumerate(allTestFiles):\n",
        "  label_name, set_name = get_label_from_path(path)\n",
        "  #print(path)\n",
        "  #print(\"Label name is : \", label_name, \"Set  name is: \", set_name)\n",
        "  #print(\"Label id is: \", get_label_id(label_name).numpy())\n",
        "  print()\n",
        "  labelReadable = label_name.numpy().decode(\"utf-8\")\n",
        "\n",
        "  audio = get_waveform_from_path(path)\n",
        "  #get_audio_plot(audio, (\"Raw wave, \" + labelReadable))\n",
        "  #get_audio_source(audio)\n",
        "\n",
        "  shifted_audio = shift_audio(audio)\n",
        "  #get_audio_plot(shifted_audio, (\"Shifted audio, \" + labelReadable))\n",
        "  #get_audio_source(shifted_audio)\n",
        "\n",
        "  noisy_audio = add_noise_to_audio(audio)\n",
        "  #get_audio_plot(noisy_audio, (\"Noisified audio, \" + labelReadable))\n",
        "  #get_audio_source(noisy_audio)\n",
        "  if itteration == 3: break"
      ],
      "metadata": {
        "id": "po6jfkbWRNG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29c10ad-a0e1-4393-c5cd-229e0769b3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1003\n",
            "['blue', 'red', 'unknown']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "commands = get_commands(datasetPath)\n",
        "print(get_model_name())\n",
        "\n",
        "print(get_seconds(1)) #Frame 1 should result in 0.5 seconds, as frame 0 is 0->1second and frame 1 is 0.5 -> 1.5 seconds"
      ],
      "metadata": {
        "id": "-J_uQdJq-Mtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08d2f3e-a99a-405b-82cf-235c7ff88b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('V6.0_simpleCNN_MSWC_blue-red-unknown_spectrogram_06-04-2022', 'V6.0_TFlite_simpleCNN_MSWC_blue-red-unknown_spectrogram_06-04-2022')\n",
            "78.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "commands = get_commands(datasetPath)\n",
        "test_ds = ds_preProcessing(\"DEV\")\n",
        "\n",
        "allTestAugmentationFiles = load_filenames(commands, \"TEMP\")\n",
        "for itteration, path in enumerate(allTestAugmentationFiles):\n",
        "  label_name, set_name = get_label_from_path(path)\n",
        "  print()\n",
        "  labelReadable = label_name.numpy().decode(\"utf-8\")\n",
        "\n",
        "  audio = get_waveform_from_path(path)\n",
        "  get_audio_plot(audio, (\"Augmented audio, \" + labelReadable))\n",
        "  get_audio_source(audio)\n",
        "  if itteration == 4: break"
      ],
      "metadata": {
        "id": "XwnMNaMSbXtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfed0e9c-5090-4b47-a324-0bf838073add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1003\n",
            "Amount of files in the set:  1003\n",
            "Tensor(\"strided_slice:0\", shape=(), dtype=string)\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset splits initialization\n",
        "Creates dataset objects containing the splits of the dataset"
      ],
      "metadata": {
        "id": "5V4lM97qRNxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#shutil.rmtree(\"/content/dataset/DEV/unknown\")\n",
        "#shutil.rmtree(\"/content/dataset/TRAIN/unknown\")\n",
        "#shutil.rmtree(\"/content/dataset/TEST/unknown\")\n",
        "\n",
        "commands = get_commands(datasetPath)\n",
        "train_ds = ds_preProcessing(\"TRAIN\") #Initialize and make each dataset split\n",
        "val_ds = ds_preProcessing(\"TEST\")\n",
        "test_ds = ds_preProcessing(\"DEV\")\n",
        "\n",
        "print(train_ds)\n",
        "\n",
        "for spectrogram, label in test_ds.take(3): #show several spectrograms\n",
        "  get_spectrogram_plot(spectrogram)\n",
        "  print(\"Minimum spectrogram\", tf.reduce_min(spectrogram), \"Maximum spectrogram value:\", tf.reduce_max(spectrogram))\n",
        "  print(label)"
      ],
      "metadata": {
        "id": "_WOFuotL9gc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6e58b2c-b419-496e-da8f-53a6e746a906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7895\n",
            "Amount of files in the set:  7895\n",
            "Data augmentation tf.Tensor(\n",
            "[b'/content/dataset/TRAIN/red/common_voice_en_8882.wav'\n",
            " b'/content/dataset/TRAIN/unknown/common_voice_nl_21413015.wav'\n",
            " b'/content/dataset/TRAIN/unknown/common_voice_nl_20876550.wav' ...\n",
            " b'/content/dataset/TRAIN/unknown/common_voice_nl_17694194.wav'\n",
            " b'/content/dataset/TRAIN/red/common_voice_en_18500434.wav'\n",
            " b'/content/dataset/TRAIN/red/common_voice_en_19475383.wav'], shape=(7895,), dtype=string)\n",
            "9817\n",
            "Tensor(\"strided_slice:0\", shape=(), dtype=string)\n",
            "1003\n",
            "Amount of files in the set:  1003\n",
            "Tensor(\"strided_slice:0\", shape=(), dtype=string)\n",
            "1003\n",
            "Amount of files in the set:  1003\n",
            "Tensor(\"strided_slice:0\", shape=(), dtype=string)\n",
            "<ParallelMapDataset element_spec=(TensorSpec(shape=(129, 124, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum spectrogram tf.Tensor(1.0693954e-11, shape=(), dtype=float32) Maximum spectrogram value: tf.Tensor(0.01681012, shape=(), dtype=float32)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum spectrogram tf.Tensor(1.0693954e-11, shape=(), dtype=float32) Maximum spectrogram value: tf.Tensor(0.011905616, shape=(), dtype=float32)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum spectrogram tf.Tensor(1.0693954e-11, shape=(), dtype=float32) Maximum spectrogram value: tf.Tensor(0.010306441, shape=(), dtype=float32)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN model training"
      ],
      "metadata": {
        "id": "qTZtHVgwp4UY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture decleration\n",
        "Creates the CNN model architectures"
      ],
      "metadata": {
        "id": "LkbC5Mta7Vxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for spectrogram, _ in test_ds.take(1): #Get the spectrogram shape and number of labels\n",
        "  input_shape = spectrogram.shape\n",
        "  input_example = spectrogram\n",
        "print('Input shape:', input_shape)\n",
        "num_labels = len(commands)\n",
        "print(\"Number of commands and ending parameters: \", num_labels)\n",
        "\n",
        "if modelType == \"simpleCNN\": #Initialize simple CNN architecture\n",
        "  # Instantiate the `tf.keras.layers.Normalization` layer.\n",
        "  norm_layer = layers.Normalization()\n",
        "  # Fit the state of the layer to the spectrograms\n",
        "  # with `Normalization.adapt`.\n",
        "  norm_layer.adapt(data=train_ds.map(map_func=lambda spec, label: spec))\n",
        "  model = models.Sequential([\n",
        "      layers.Input(shape=input_shape),\n",
        "      # Downsample the input.\n",
        "      layers.Resizing(32, 32),\n",
        "      # Normalize.\n",
        "      norm_layer,\n",
        "      layers.Conv2D(32, 3, activation='relu'),\n",
        "      layers.Conv2D(64, 3, activation='relu'),\n",
        "      layers.MaxPooling2D(),\n",
        "      layers.Dropout(0.25),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dropout(0.5),\n",
        "      layers.Dense(num_labels),\n",
        "      ])\n",
        "  print(\"Made an simpleCNN model!\")\n",
        "\n",
        "elif modelType == \"mobileNetV1\": #Initialize MobileNetV1 architecture\n",
        "  model = tf.keras.applications.MobileNet(input_shape=input_shape, classes=num_labels, weights=None, \n",
        "                                          alpha=alphaMobileNet, dropout=dropoutMobileNet)\n",
        "  print(\"Made an mobileNetV1 model!\")\n",
        "\n",
        "elif modelType == \"mobileNetV2\": #Initialize MobileNetV2 architecture\n",
        "  model = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=input_shape, classes=num_labels, weights=None,\n",
        "                                                         alpha=alphaMobileNet)\n",
        "  print(\"Made an mobileNetV2 model!\")\n",
        "elif modelType == \"mobileNetV3\": #Initialize MobileNetV3 architecture\n",
        "  mobileNetLayers.layers = tf.keras.applications.MobileNetV3Small(input_shape=input_shape, classes=num_labels, weights=None,  #Load the mobileNet architecture with no weights(not pretrained).\n",
        "                                    minimalistic=False, include_preprocessing=normalize_spectrogram_bool, alpha=alphaMobileNet, #Can have a \"top\" meaning it is a full architecture with fully connected layer, or can be False which means a manual fully connected layer should be added\n",
        "                                    include_top=False, pooling=\"avg\", dropout_rate=0.4) #If include top is false, pooling should be average(\"avg\")\n",
        "  for layer in mobileNetLayers.layers:\n",
        "    layer.trainable = True #Set mobilenet layers to be trainable\n",
        "\n",
        "  model = models.Sequential() #Make new model containing the mobileNet architecture + fully connected layers\n",
        "  model.add(mobileNetLayers) #Add mobileNet layers to model\n",
        "\n",
        "  model.add(layers.Dropout(0.25)) #Delete some of the output of the mobileNet layers, reduces chance for overfitting\n",
        "  model.add(layers.Flatten()) #Flatten the output to a 1D array\n",
        "  model.add(layers.Dense(128, activation='relu')) #Add fully connected layer that outputs a 128x1 array\n",
        "  model.add(layers.Dropout(0.5)) #Delete some of the output\n",
        "  model.add(layers.Dense(num_labels)) #Add another fully connected layer that performs the final prediction, outputs one of the labels\n",
        "\n",
        "  print(\"Made an mobileNetV3 model!\")\n",
        "\n",
        "elif modelType == \"efficientNet\": #Initialize efficientNet architecture(for testing)\n",
        "  model = tf.keras.applications.efficientnet.EfficientNetB0(input_shape=input_shape, weights=None, include_top=True, classes=num_labels, classifier_activation=\"relu\")\n",
        "  print(\"Made an efficientNet model!\")   \n",
        "\n",
        "else: print(\"Error, modeltype not set to valid model\")"
      ],
      "metadata": {
        "id": "Q-kCI8XipR0F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "168abb6f-78ae-43f4-d0d6-a7046c31fcd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (129, 124, 1)\n",
            "Number of commands and ending parameters:  3\n",
            "Model: \"MobilenetV3small\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 129, 124, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " Conv (Conv2D)                  (None, 65, 62, 16)   144         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " Conv/BatchNorm (BatchNormaliza  (None, 65, 62, 16)  64          ['Conv[0][0]']                   \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 65, 62, 16)  0           ['Conv/BatchNorm[0][0]']         \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                   (None, 65, 62, 16)   0           ['tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None, 65, 62, 16)   0           ['re_lu[0][0]']                  \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 65, 62, 16)   0           ['Conv/BatchNorm[0][0]',         \n",
            "                                                                  'tf.math.multiply[0][0]']       \n",
            "                                                                                                  \n",
            " expanded_conv/depthwise/pad (Z  (None, 67, 63, 16)  0           ['multiply[0][0]']               \n",
            " eroPadding2D)                                                                                    \n",
            "                                                                                                  \n",
            " expanded_conv/depthwise (Depth  (None, 33, 31, 16)  144         ['expanded_conv/depthwise/pad[0][\n",
            " wiseConv2D)                                                     0]']                             \n",
            "                                                                                                  \n",
            " expanded_conv/depthwise/BatchN  (None, 33, 31, 16)  64          ['expanded_conv/depthwise[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 33, 31, 16)   0           ['expanded_conv/depthwise/BatchNo\n",
            "                                                                 rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv/squeeze_excite/A  (None, 1, 1, 16)    0           ['re_lu_1[0][0]']                \n",
            " vgPool (GlobalAveragePooling2D                                                                   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv/squeeze_excite/C  (None, 1, 1, 8)     136         ['expanded_conv/squeeze_excite/Av\n",
            " onv (Conv2D)                                                    gPool[0][0]']                    \n",
            "                                                                                                  \n",
            " expanded_conv/squeeze_excite/R  (None, 1, 1, 8)     0           ['expanded_conv/squeeze_excite/Co\n",
            " elu (ReLU)                                                      nv[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv/squeeze_excite/C  (None, 1, 1, 16)    144         ['expanded_conv/squeeze_excite/Re\n",
            " onv_1 (Conv2D)                                                  lu[0][0]']                       \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 1, 1, 16)    0           ['expanded_conv/squeeze_excite/Co\n",
            " mbda)                                                           nv_1[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 1, 1, 16)     0           ['tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_1 (TFOpLambda  (None, 1, 1, 16)    0           ['re_lu_2[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv/squeeze_excite/M  (None, 33, 31, 16)  0           ['re_lu_1[0][0]',                \n",
            " ul (Multiply)                                                    'tf.math.multiply_1[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv/project (Conv2D)  (None, 33, 31, 16)  256         ['expanded_conv/squeeze_excite/Mu\n",
            "                                                                 l[0][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv/project/BatchNor  (None, 33, 31, 16)  64          ['expanded_conv/project[0][0]']  \n",
            " m (BatchNormalization)                                                                           \n",
            "                                                                                                  \n",
            " expanded_conv_1/expand (Conv2D  (None, 33, 31, 72)  1152        ['expanded_conv/project/BatchNorm\n",
            " )                                                               [0][0]']                         \n",
            "                                                                                                  \n",
            " expanded_conv_1/expand/BatchNo  (None, 33, 31, 72)  288         ['expanded_conv_1/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 33, 31, 72)   0           ['expanded_conv_1/expand/BatchNor\n",
            "                                                                 m[0][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv_1/depthwise/pad   (None, 35, 33, 72)  0           ['re_lu_3[0][0]']                \n",
            " (ZeroPadding2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_1/depthwise (Dep  (None, 17, 16, 72)  648         ['expanded_conv_1/depthwise/pad[0\n",
            " thwiseConv2D)                                                   ][0]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_1/depthwise/Batc  (None, 17, 16, 72)  288         ['expanded_conv_1/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 17, 16, 72)   0           ['expanded_conv_1/depthwise/Batch\n",
            "                                                                 Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_1/project (Conv2  (None, 17, 16, 16)  1152        ['re_lu_4[0][0]']                \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_1/project/BatchN  (None, 17, 16, 16)  64          ['expanded_conv_1/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_2/expand (Conv2D  (None, 17, 16, 56)  896         ['expanded_conv_1/project/BatchNo\n",
            " )                                                               rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_2/expand/BatchNo  (None, 17, 16, 56)  224         ['expanded_conv_2/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)                 (None, 17, 16, 56)   0           ['expanded_conv_2/expand/BatchNor\n",
            "                                                                 m[0][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv_2/depthwise (Dep  (None, 17, 16, 56)  504         ['re_lu_5[0][0]']                \n",
            " thwiseConv2D)                                                                                    \n",
            "                                                                                                  \n",
            " expanded_conv_2/depthwise/Batc  (None, 17, 16, 56)  224         ['expanded_conv_2/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)                 (None, 17, 16, 56)   0           ['expanded_conv_2/depthwise/Batch\n",
            "                                                                 Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_2/project (Conv2  (None, 17, 16, 16)  896         ['re_lu_6[0][0]']                \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_2/project/BatchN  (None, 17, 16, 16)  64          ['expanded_conv_2/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_2/Add (Add)      (None, 17, 16, 16)   0           ['expanded_conv_1/project/BatchNo\n",
            "                                                                 rm[0][0]',                       \n",
            "                                                                  'expanded_conv_2/project/BatchNo\n",
            "                                                                 rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_3/expand (Conv2D  (None, 17, 16, 64)  1024        ['expanded_conv_2/Add[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_3/expand/BatchNo  (None, 17, 16, 64)  256         ['expanded_conv_3/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 17, 16, 64)  0           ['expanded_conv_3/expand/BatchNor\n",
            " mbda)                                                           m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)                 (None, 17, 16, 64)   0           ['tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_2 (TFOpLambda  (None, 17, 16, 64)  0           ['re_lu_7[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 17, 16, 64)   0           ['expanded_conv_3/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_2[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_3/depthwise/pad   (None, 21, 19, 64)  0           ['multiply_1[0][0]']             \n",
            " (ZeroPadding2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_3/depthwise (Dep  (None, 9, 8, 64)    1600        ['expanded_conv_3/depthwise/pad[0\n",
            " thwiseConv2D)                                                   ][0]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_3/depthwise/Batc  (None, 9, 8, 64)    256         ['expanded_conv_3/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 9, 8, 64)    0           ['expanded_conv_3/depthwise/Batch\n",
            " mbda)                                                           Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 9, 8, 64)     0           ['tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_3 (TFOpLambda  (None, 9, 8, 64)    0           ['re_lu_8[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 9, 8, 64)     0           ['expanded_conv_3/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_3[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_3/squeeze_excite  (None, 1, 1, 64)    0           ['multiply_2[0][0]']             \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_3/squeeze_excite  (None, 1, 1, 16)    1040        ['expanded_conv_3/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_3/squeeze_excite  (None, 1, 1, 16)    0           ['expanded_conv_3/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_3/squeeze_excite  (None, 1, 1, 64)    1088        ['expanded_conv_3/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 1, 1, 64)    0           ['expanded_conv_3/squeeze_excite/\n",
            " mbda)                                                           Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)                 (None, 1, 1, 64)     0           ['tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_4 (TFOpLambda  (None, 1, 1, 64)    0           ['re_lu_9[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_3/squeeze_excite  (None, 9, 8, 64)    0           ['multiply_2[0][0]',             \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_4[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_3/project (Conv2  (None, 9, 8, 32)    2048        ['expanded_conv_3/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_3/project/BatchN  (None, 9, 8, 32)    128         ['expanded_conv_3/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_4/expand (Conv2D  (None, 9, 8, 192)   6144        ['expanded_conv_3/project/BatchNo\n",
            " )                                                               rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_4/expand/BatchNo  (None, 9, 8, 192)   768         ['expanded_conv_4/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None, 9, 8, 192)   0           ['expanded_conv_4/expand/BatchNor\n",
            " mbda)                                                           m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)                (None, 9, 8, 192)    0           ['tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_5 (TFOpLambda  (None, 9, 8, 192)   0           ['re_lu_10[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 9, 8, 192)    0           ['expanded_conv_4/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_5[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_4/depthwise (Dep  (None, 9, 8, 192)   4800        ['multiply_3[0][0]']             \n",
            " thwiseConv2D)                                                                                    \n",
            "                                                                                                  \n",
            " expanded_conv_4/depthwise/Batc  (None, 9, 8, 192)   768         ['expanded_conv_4/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (None, 9, 8, 192)   0           ['expanded_conv_4/depthwise/Batch\n",
            " mbda)                                                           Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)                (None, 9, 8, 192)    0           ['tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_6 (TFOpLambda  (None, 9, 8, 192)   0           ['re_lu_11[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 9, 8, 192)    0           ['expanded_conv_4/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_6[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_4/squeeze_excite  (None, 1, 1, 192)   0           ['multiply_4[0][0]']             \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_4/squeeze_excite  (None, 1, 1, 48)    9264        ['expanded_conv_4/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_4/squeeze_excite  (None, 1, 1, 48)    0           ['expanded_conv_4/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_4/squeeze_excite  (None, 1, 1, 192)   9408        ['expanded_conv_4/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (None, 1, 1, 192)   0           ['expanded_conv_4/squeeze_excite/\n",
            " mbda)                                                           Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)                (None, 1, 1, 192)    0           ['tf.__operators__.add_7[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_7 (TFOpLambda  (None, 1, 1, 192)   0           ['re_lu_12[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_4/squeeze_excite  (None, 9, 8, 192)   0           ['multiply_4[0][0]',             \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_7[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_4/project (Conv2  (None, 9, 8, 32)    6144        ['expanded_conv_4/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_4/project/BatchN  (None, 9, 8, 32)    128         ['expanded_conv_4/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_4/Add (Add)      (None, 9, 8, 32)     0           ['expanded_conv_3/project/BatchNo\n",
            "                                                                 rm[0][0]',                       \n",
            "                                                                  'expanded_conv_4/project/BatchNo\n",
            "                                                                 rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_5/expand (Conv2D  (None, 9, 8, 192)   6144        ['expanded_conv_4/Add[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_5/expand/BatchNo  (None, 9, 8, 192)   768         ['expanded_conv_5/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_8 (TFOpLa  (None, 9, 8, 192)   0           ['expanded_conv_5/expand/BatchNor\n",
            " mbda)                                                           m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)                (None, 9, 8, 192)    0           ['tf.__operators__.add_8[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_8 (TFOpLambda  (None, 9, 8, 192)   0           ['re_lu_13[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 9, 8, 192)    0           ['expanded_conv_5/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_8[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_5/depthwise (Dep  (None, 9, 8, 192)   4800        ['multiply_5[0][0]']             \n",
            " thwiseConv2D)                                                                                    \n",
            "                                                                                                  \n",
            " expanded_conv_5/depthwise/Batc  (None, 9, 8, 192)   768         ['expanded_conv_5/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_9 (TFOpLa  (None, 9, 8, 192)   0           ['expanded_conv_5/depthwise/Batch\n",
            " mbda)                                                           Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)                (None, 9, 8, 192)    0           ['tf.__operators__.add_9[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_9 (TFOpLambda  (None, 9, 8, 192)   0           ['re_lu_14[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 9, 8, 192)    0           ['expanded_conv_5/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_9[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_5/squeeze_excite  (None, 1, 1, 192)   0           ['multiply_6[0][0]']             \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_5/squeeze_excite  (None, 1, 1, 48)    9264        ['expanded_conv_5/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_5/squeeze_excite  (None, 1, 1, 48)    0           ['expanded_conv_5/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_5/squeeze_excite  (None, 1, 1, 192)   9408        ['expanded_conv_5/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_10 (TFOpL  (None, 1, 1, 192)   0           ['expanded_conv_5/squeeze_excite/\n",
            " ambda)                                                          Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)                (None, 1, 1, 192)    0           ['tf.__operators__.add_10[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_10 (TFOpLambd  (None, 1, 1, 192)   0           ['re_lu_15[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_5/squeeze_excite  (None, 9, 8, 192)   0           ['multiply_6[0][0]',             \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_10[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_5/project (Conv2  (None, 9, 8, 32)    6144        ['expanded_conv_5/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_5/project/BatchN  (None, 9, 8, 32)    128         ['expanded_conv_5/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_5/Add (Add)      (None, 9, 8, 32)     0           ['expanded_conv_4/Add[0][0]',    \n",
            "                                                                  'expanded_conv_5/project/BatchNo\n",
            "                                                                 rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_6/expand (Conv2D  (None, 9, 8, 96)    3072        ['expanded_conv_5/Add[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_6/expand/BatchNo  (None, 9, 8, 96)    384         ['expanded_conv_6/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_11 (TFOpL  (None, 9, 8, 96)    0           ['expanded_conv_6/expand/BatchNor\n",
            " ambda)                                                          m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)                (None, 9, 8, 96)     0           ['tf.__operators__.add_11[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_11 (TFOpLambd  (None, 9, 8, 96)    0           ['re_lu_16[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 9, 8, 96)     0           ['expanded_conv_6/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_11[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_6/depthwise (Dep  (None, 9, 8, 96)    2400        ['multiply_7[0][0]']             \n",
            " thwiseConv2D)                                                                                    \n",
            "                                                                                                  \n",
            " expanded_conv_6/depthwise/Batc  (None, 9, 8, 96)    384         ['expanded_conv_6/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_12 (TFOpL  (None, 9, 8, 96)    0           ['expanded_conv_6/depthwise/Batch\n",
            " ambda)                                                          Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)                (None, 9, 8, 96)     0           ['tf.__operators__.add_12[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_12 (TFOpLambd  (None, 9, 8, 96)    0           ['re_lu_17[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 9, 8, 96)     0           ['expanded_conv_6/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_12[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_6/squeeze_excite  (None, 1, 1, 96)    0           ['multiply_8[0][0]']             \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_6/squeeze_excite  (None, 1, 1, 24)    2328        ['expanded_conv_6/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_6/squeeze_excite  (None, 1, 1, 24)    0           ['expanded_conv_6/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_6/squeeze_excite  (None, 1, 1, 96)    2400        ['expanded_conv_6/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_13 (TFOpL  (None, 1, 1, 96)    0           ['expanded_conv_6/squeeze_excite/\n",
            " ambda)                                                          Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)                (None, 1, 1, 96)     0           ['tf.__operators__.add_13[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_13 (TFOpLambd  (None, 1, 1, 96)    0           ['re_lu_18[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_6/squeeze_excite  (None, 9, 8, 96)    0           ['multiply_8[0][0]',             \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_13[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_6/project (Conv2  (None, 9, 8, 32)    3072        ['expanded_conv_6/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_6/project/BatchN  (None, 9, 8, 32)    128         ['expanded_conv_6/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_6/Add (Add)      (None, 9, 8, 32)     0           ['expanded_conv_5/Add[0][0]',    \n",
            "                                                                  'expanded_conv_6/project/BatchNo\n",
            "                                                                 rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_7/expand (Conv2D  (None, 9, 8, 96)    3072        ['expanded_conv_6/Add[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_7/expand/BatchNo  (None, 9, 8, 96)    384         ['expanded_conv_7/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_14 (TFOpL  (None, 9, 8, 96)    0           ['expanded_conv_7/expand/BatchNor\n",
            " ambda)                                                          m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)                (None, 9, 8, 96)     0           ['tf.__operators__.add_14[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_14 (TFOpLambd  (None, 9, 8, 96)    0           ['re_lu_19[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 9, 8, 96)     0           ['expanded_conv_7/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_14[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_7/depthwise (Dep  (None, 9, 8, 96)    2400        ['multiply_9[0][0]']             \n",
            " thwiseConv2D)                                                                                    \n",
            "                                                                                                  \n",
            " expanded_conv_7/depthwise/Batc  (None, 9, 8, 96)    384         ['expanded_conv_7/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_15 (TFOpL  (None, 9, 8, 96)    0           ['expanded_conv_7/depthwise/Batch\n",
            " ambda)                                                          Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)                (None, 9, 8, 96)     0           ['tf.__operators__.add_15[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_15 (TFOpLambd  (None, 9, 8, 96)    0           ['re_lu_20[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 9, 8, 96)     0           ['expanded_conv_7/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_15[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_7/squeeze_excite  (None, 1, 1, 96)    0           ['multiply_10[0][0]']            \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_7/squeeze_excite  (None, 1, 1, 24)    2328        ['expanded_conv_7/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_7/squeeze_excite  (None, 1, 1, 24)    0           ['expanded_conv_7/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_7/squeeze_excite  (None, 1, 1, 96)    2400        ['expanded_conv_7/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_16 (TFOpL  (None, 1, 1, 96)    0           ['expanded_conv_7/squeeze_excite/\n",
            " ambda)                                                          Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)                (None, 1, 1, 96)     0           ['tf.__operators__.add_16[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_16 (TFOpLambd  (None, 1, 1, 96)    0           ['re_lu_21[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_7/squeeze_excite  (None, 9, 8, 96)    0           ['multiply_10[0][0]',            \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_16[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_7/project (Conv2  (None, 9, 8, 32)    3072        ['expanded_conv_7/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_7/project/BatchN  (None, 9, 8, 32)    128         ['expanded_conv_7/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_7/Add (Add)      (None, 9, 8, 32)     0           ['expanded_conv_6/Add[0][0]',    \n",
            "                                                                  'expanded_conv_7/project/BatchNo\n",
            "                                                                 rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_8/expand (Conv2D  (None, 9, 8, 192)   6144        ['expanded_conv_7/Add[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_8/expand/BatchNo  (None, 9, 8, 192)   768         ['expanded_conv_8/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_17 (TFOpL  (None, 9, 8, 192)   0           ['expanded_conv_8/expand/BatchNor\n",
            " ambda)                                                          m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)                (None, 9, 8, 192)    0           ['tf.__operators__.add_17[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_17 (TFOpLambd  (None, 9, 8, 192)   0           ['re_lu_22[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 9, 8, 192)    0           ['expanded_conv_8/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_17[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_8/depthwise/pad   (None, 13, 11, 192)  0          ['multiply_11[0][0]']            \n",
            " (ZeroPadding2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_8/depthwise (Dep  (None, 5, 4, 192)   4800        ['expanded_conv_8/depthwise/pad[0\n",
            " thwiseConv2D)                                                   ][0]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_8/depthwise/Batc  (None, 5, 4, 192)   768         ['expanded_conv_8/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_18 (TFOpL  (None, 5, 4, 192)   0           ['expanded_conv_8/depthwise/Batch\n",
            " ambda)                                                          Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_23 (ReLU)                (None, 5, 4, 192)    0           ['tf.__operators__.add_18[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_18 (TFOpLambd  (None, 5, 4, 192)   0           ['re_lu_23[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 4, 192)    0           ['expanded_conv_8/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_18[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_8/squeeze_excite  (None, 1, 1, 192)   0           ['multiply_12[0][0]']            \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_8/squeeze_excite  (None, 1, 1, 48)    9264        ['expanded_conv_8/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_8/squeeze_excite  (None, 1, 1, 48)    0           ['expanded_conv_8/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_8/squeeze_excite  (None, 1, 1, 192)   9408        ['expanded_conv_8/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_19 (TFOpL  (None, 1, 1, 192)   0           ['expanded_conv_8/squeeze_excite/\n",
            " ambda)                                                          Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_24 (ReLU)                (None, 1, 1, 192)    0           ['tf.__operators__.add_19[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_19 (TFOpLambd  (None, 1, 1, 192)   0           ['re_lu_24[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_8/squeeze_excite  (None, 5, 4, 192)   0           ['multiply_12[0][0]',            \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_19[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_8/project (Conv2  (None, 5, 4, 64)    12288       ['expanded_conv_8/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_8/project/BatchN  (None, 5, 4, 64)    256         ['expanded_conv_8/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_9/expand (Conv2D  (None, 5, 4, 384)   24576       ['expanded_conv_8/project/BatchNo\n",
            " )                                                               rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_9/expand/BatchNo  (None, 5, 4, 384)   1536        ['expanded_conv_9/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_20 (TFOpL  (None, 5, 4, 384)   0           ['expanded_conv_9/expand/BatchNor\n",
            " ambda)                                                          m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_25 (ReLU)                (None, 5, 4, 384)    0           ['tf.__operators__.add_20[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_20 (TFOpLambd  (None, 5, 4, 384)   0           ['re_lu_25[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 4, 384)    0           ['expanded_conv_9/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_20[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_9/depthwise (Dep  (None, 5, 4, 384)   9600        ['multiply_13[0][0]']            \n",
            " thwiseConv2D)                                                                                    \n",
            "                                                                                                  \n",
            " expanded_conv_9/depthwise/Batc  (None, 5, 4, 384)   1536        ['expanded_conv_9/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_21 (TFOpL  (None, 5, 4, 384)   0           ['expanded_conv_9/depthwise/Batch\n",
            " ambda)                                                          Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_26 (ReLU)                (None, 5, 4, 384)    0           ['tf.__operators__.add_21[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_21 (TFOpLambd  (None, 5, 4, 384)   0           ['re_lu_26[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 4, 384)    0           ['expanded_conv_9/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_21[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_9/squeeze_excite  (None, 1, 1, 384)   0           ['multiply_14[0][0]']            \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_9/squeeze_excite  (None, 1, 1, 96)    36960       ['expanded_conv_9/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_9/squeeze_excite  (None, 1, 1, 96)    0           ['expanded_conv_9/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_9/squeeze_excite  (None, 1, 1, 384)   37248       ['expanded_conv_9/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_22 (TFOpL  (None, 1, 1, 384)   0           ['expanded_conv_9/squeeze_excite/\n",
            " ambda)                                                          Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_27 (ReLU)                (None, 1, 1, 384)    0           ['tf.__operators__.add_22[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_22 (TFOpLambd  (None, 1, 1, 384)   0           ['re_lu_27[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_9/squeeze_excite  (None, 5, 4, 384)   0           ['multiply_14[0][0]',            \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_22[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_9/project (Conv2  (None, 5, 4, 64)    24576       ['expanded_conv_9/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_9/project/BatchN  (None, 5, 4, 64)    256         ['expanded_conv_9/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_9/Add (Add)      (None, 5, 4, 64)     0           ['expanded_conv_8/project/BatchNo\n",
            "                                                                 rm[0][0]',                       \n",
            "                                                                  'expanded_conv_9/project/BatchNo\n",
            "                                                                 rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_10/expand (Conv2  (None, 5, 4, 384)   24576       ['expanded_conv_9/Add[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_10/expand/BatchN  (None, 5, 4, 384)   1536        ['expanded_conv_10/expand[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " tf.__operators__.add_23 (TFOpL  (None, 5, 4, 384)   0           ['expanded_conv_10/expand/BatchNo\n",
            " ambda)                                                          rm[0][0]']                       \n",
            "                                                                                                  \n",
            " re_lu_28 (ReLU)                (None, 5, 4, 384)    0           ['tf.__operators__.add_23[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_23 (TFOpLambd  (None, 5, 4, 384)   0           ['re_lu_28[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 4, 384)    0           ['expanded_conv_10/expand/BatchNo\n",
            "                                                                 rm[0][0]',                       \n",
            "                                                                  'tf.math.multiply_23[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_10/depthwise (De  (None, 5, 4, 384)   9600        ['multiply_15[0][0]']            \n",
            " pthwiseConv2D)                                                                                   \n",
            "                                                                                                  \n",
            " expanded_conv_10/depthwise/Bat  (None, 5, 4, 384)   1536        ['expanded_conv_10/depthwise[0][0\n",
            " chNorm (BatchNormalization)                                     ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_24 (TFOpL  (None, 5, 4, 384)   0           ['expanded_conv_10/depthwise/Batc\n",
            " ambda)                                                          hNorm[0][0]']                    \n",
            "                                                                                                  \n",
            " re_lu_29 (ReLU)                (None, 5, 4, 384)    0           ['tf.__operators__.add_24[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_24 (TFOpLambd  (None, 5, 4, 384)   0           ['re_lu_29[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_16 (Multiply)         (None, 5, 4, 384)    0           ['expanded_conv_10/depthwise/Batc\n",
            "                                                                 hNorm[0][0]',                    \n",
            "                                                                  'tf.math.multiply_24[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_10/squeeze_excit  (None, 1, 1, 384)   0           ['multiply_16[0][0]']            \n",
            " e/AvgPool (GlobalAveragePoolin                                                                   \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " expanded_conv_10/squeeze_excit  (None, 1, 1, 96)    36960       ['expanded_conv_10/squeeze_excite\n",
            " e/Conv (Conv2D)                                                 /AvgPool[0][0]']                 \n",
            "                                                                                                  \n",
            " expanded_conv_10/squeeze_excit  (None, 1, 1, 96)    0           ['expanded_conv_10/squeeze_excite\n",
            " e/Relu (ReLU)                                                   /Conv[0][0]']                    \n",
            "                                                                                                  \n",
            " expanded_conv_10/squeeze_excit  (None, 1, 1, 384)   37248       ['expanded_conv_10/squeeze_excite\n",
            " e/Conv_1 (Conv2D)                                               /Relu[0][0]']                    \n",
            "                                                                                                  \n",
            " tf.__operators__.add_25 (TFOpL  (None, 1, 1, 384)   0           ['expanded_conv_10/squeeze_excite\n",
            " ambda)                                                          /Conv_1[0][0]']                  \n",
            "                                                                                                  \n",
            " re_lu_30 (ReLU)                (None, 1, 1, 384)    0           ['tf.__operators__.add_25[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_25 (TFOpLambd  (None, 1, 1, 384)   0           ['re_lu_30[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_10/squeeze_excit  (None, 5, 4, 384)   0           ['multiply_16[0][0]',            \n",
            " e/Mul (Multiply)                                                 'tf.math.multiply_25[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_10/project (Conv  (None, 5, 4, 64)    24576       ['expanded_conv_10/squeeze_excite\n",
            " 2D)                                                             /Mul[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_10/project/Batch  (None, 5, 4, 64)    256         ['expanded_conv_10/project[0][0]'\n",
            " Norm (BatchNormalization)                                       ]                                \n",
            "                                                                                                  \n",
            " expanded_conv_10/Add (Add)     (None, 5, 4, 64)     0           ['expanded_conv_9/Add[0][0]',    \n",
            "                                                                  'expanded_conv_10/project/BatchN\n",
            "                                                                 orm[0][0]']                      \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 5, 4, 384)    24576       ['expanded_conv_10/Add[0][0]']   \n",
            "                                                                                                  \n",
            " Conv_1/BatchNorm (BatchNormali  (None, 5, 4, 384)   1536        ['Conv_1[0][0]']                 \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_26 (TFOpL  (None, 5, 4, 384)   0           ['Conv_1/BatchNorm[0][0]']       \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " re_lu_31 (ReLU)                (None, 5, 4, 384)    0           ['tf.__operators__.add_26[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_26 (TFOpLambd  (None, 5, 4, 384)   0           ['re_lu_31[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_17 (Multiply)         (None, 5, 4, 384)    0           ['Conv_1/BatchNorm[0][0]',       \n",
            "                                                                  'tf.math.multiply_26[0][0]']    \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 384)         0           ['multiply_17[0][0]']            \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 460,424\n",
            "Trainable params: 451,880\n",
            "Non-trainable params: 8,544\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-32ce999b826f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmobileNetLayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mobileNetLayers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics & Callbacks\n",
        "Configures the metrics and settings of the model that are to be used for training"
      ],
      "metadata": {
        "id": "3j8CvRqzqCmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model settings\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam() #Handles the weight itterations of the model during training\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) #How to calculate the loss of the model during training, from_logits should be set to True! Atleast for the simpleCNN \n",
        "metrics = [tf.keras.metrics.sparse_categorical_accuracy] #How to calculate the performance of the model\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics) #Create a usable model with all settings\n",
        "model.summary() #Display the model architecture\n",
        "\n",
        "#Training callback settings\n",
        "weight_path=\"{}_weights.best.hdf5\".format(modelType) #Path where to save the best weights\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, #Saves model weights during training when a new best is found, allows for a backup if training crashes\n",
        "                             save_best_only=True, mode='min', save_weights_only = True) \n",
        "reduceLROnPlat = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', #Reduces Learning rate when training stagnates, allows more training to take place\n",
        "                                   factor=0.8, patience=2, \n",
        "                                   verbose=1, mode='auto', \n",
        "                                   min_delta=0.0001, cooldown=5, \n",
        "                                   min_lr=0.00001)\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", #Stops training if the validation loss does not improve for x Epochs(Set by the patience variable)\n",
        "                      mode=\"min\", \n",
        "                      patience=6)\n",
        "callback_list = [checkpoint, early, reduceLROnPlat] #Afforementioned functions that will be performed after each epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8aN-Q1yFKQQ",
        "outputId": "c32779e6-a63a-4d2e-a6c8-419116943982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resizing (Resizing)         (None, 32, 32, 1)         0         \n",
            "                                                                 \n",
            " normalization (Normalizatio  (None, 32, 32, 1)        3         \n",
            " n)                                                              \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1605760   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,624,966\n",
            "Trainable params: 1,624,963\n",
            "Non-trainable params: 3\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "Training execution of the model"
      ],
      "metadata": {
        "id": "q8EgdRnWqR0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.batch(batch_size) #Devides the splits into batches, improves training performance and speed\n",
        "val_ds = val_ds.batch(batch_size)\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(AUTOTUNE) #Preload the batches\n",
        "val_ds = val_ds.cache().prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "wP_8EP59r52z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if device_name == '/device:GPU:0':\n",
        "  with tf.device('/device:GPU:0'): #Perform training with GPU device for faster training\n",
        "    history = model.fit(\n",
        "      train_ds, batch_size=batch_size,\n",
        "      validation_data=val_ds,\n",
        "      callbacks=[callback_list], #Call the callback_list containing the checkpoint saving, learning rate reduction and early stopping after each EPOCH\n",
        "      epochs=EPOCHS, verbose=1)\n",
        "else: #If GPU is not available, run on CPU\n",
        "    history = model.fit(\n",
        "      train_ds, batch_size=batch_size,\n",
        "      validation_data=val_ds,\n",
        "      callbacks=[callback_list],\n",
        "      epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gpgbncoyauc_",
        "outputId": "0c5f02fc-372f-4c6a-d9ed-9b1c5e1e97ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.5652 - sparse_categorical_accuracy: 0.7979\n",
            "Epoch 1: val_loss improved from inf to 0.40258, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 22s 85ms/step - loss: 0.5652 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.4026 - val_sparse_categorical_accuracy: 0.8674 - lr: 0.0010\n",
            "Epoch 2/60\n",
            "144/154 [===========================>..] - ETA: 0s - loss: 0.3909 - sparse_categorical_accuracy: 0.8567\n",
            "Epoch 2: val_loss improved from 0.40258 to 0.32103, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.3884 - sparse_categorical_accuracy: 0.8566 - val_loss: 0.3210 - val_sparse_categorical_accuracy: 0.8923 - lr: 0.0010\n",
            "Epoch 3/60\n",
            "144/154 [===========================>..] - ETA: 0s - loss: 0.3270 - sparse_categorical_accuracy: 0.8808\n",
            "Epoch 3: val_loss improved from 0.32103 to 0.31336, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.3274 - sparse_categorical_accuracy: 0.8807 - val_loss: 0.3134 - val_sparse_categorical_accuracy: 0.8973 - lr: 0.0010\n",
            "Epoch 4/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.2912 - sparse_categorical_accuracy: 0.8919\n",
            "Epoch 4: val_loss improved from 0.31336 to 0.28159, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.2896 - sparse_categorical_accuracy: 0.8934 - val_loss: 0.2816 - val_sparse_categorical_accuracy: 0.9033 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.2571 - sparse_categorical_accuracy: 0.9047\n",
            "Epoch 5: val_loss improved from 0.28159 to 0.23132, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.2575 - sparse_categorical_accuracy: 0.9046 - val_loss: 0.2313 - val_sparse_categorical_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 6/60\n",
            "143/154 [==========================>...] - ETA: 0s - loss: 0.2275 - sparse_categorical_accuracy: 0.9124\n",
            "Epoch 6: val_loss improved from 0.23132 to 0.22589, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.2290 - sparse_categorical_accuracy: 0.9117 - val_loss: 0.2259 - val_sparse_categorical_accuracy: 0.9262 - lr: 0.0010\n",
            "Epoch 7/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.2055 - sparse_categorical_accuracy: 0.9245\n",
            "Epoch 7: val_loss improved from 0.22589 to 0.19502, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.2057 - sparse_categorical_accuracy: 0.9247 - val_loss: 0.1950 - val_sparse_categorical_accuracy: 0.9232 - lr: 0.0010\n",
            "Epoch 8/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.1889 - sparse_categorical_accuracy: 0.9327\n",
            "Epoch 8: val_loss did not improve from 0.19502\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.1895 - sparse_categorical_accuracy: 0.9322 - val_loss: 0.2028 - val_sparse_categorical_accuracy: 0.9312 - lr: 0.0010\n",
            "Epoch 9/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.1751 - sparse_categorical_accuracy: 0.9345\n",
            "Epoch 9: val_loss improved from 0.19502 to 0.19277, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.1755 - sparse_categorical_accuracy: 0.9344 - val_loss: 0.1928 - val_sparse_categorical_accuracy: 0.9332 - lr: 0.0010\n",
            "Epoch 10/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.1590 - sparse_categorical_accuracy: 0.9422\n",
            "Epoch 10: val_loss improved from 0.19277 to 0.18922, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.1586 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.1892 - val_sparse_categorical_accuracy: 0.9392 - lr: 0.0010\n",
            "Epoch 11/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.1509 - sparse_categorical_accuracy: 0.9439\n",
            "Epoch 11: val_loss improved from 0.18922 to 0.17083, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.1517 - sparse_categorical_accuracy: 0.9437 - val_loss: 0.1708 - val_sparse_categorical_accuracy: 0.9442 - lr: 0.0010\n",
            "Epoch 12/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.1428 - sparse_categorical_accuracy: 0.9496\n",
            "Epoch 12: val_loss did not improve from 0.17083\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.1444 - sparse_categorical_accuracy: 0.9485 - val_loss: 0.1750 - val_sparse_categorical_accuracy: 0.9422 - lr: 0.0010\n",
            "Epoch 13/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.1305 - sparse_categorical_accuracy: 0.9548\n",
            "Epoch 13: val_loss improved from 0.17083 to 0.16876, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.1317 - sparse_categorical_accuracy: 0.9541 - val_loss: 0.1688 - val_sparse_categorical_accuracy: 0.9501 - lr: 0.0010\n",
            "Epoch 14/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.1220 - sparse_categorical_accuracy: 0.9559\n",
            "Epoch 14: val_loss did not improve from 0.16876\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.1206 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.1983 - val_sparse_categorical_accuracy: 0.9432 - lr: 0.0010\n",
            "Epoch 15/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.1189 - sparse_categorical_accuracy: 0.9554\n",
            "Epoch 15: val_loss improved from 0.16876 to 0.15853, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.1175 - sparse_categorical_accuracy: 0.9560 - val_loss: 0.1585 - val_sparse_categorical_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 16/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.1096 - sparse_categorical_accuracy: 0.9599\n",
            "Epoch 16: val_loss improved from 0.15853 to 0.15590, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.1109 - sparse_categorical_accuracy: 0.9598 - val_loss: 0.1559 - val_sparse_categorical_accuracy: 0.9531 - lr: 0.0010\n",
            "Epoch 17/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.1002 - sparse_categorical_accuracy: 0.9630\n",
            "Epoch 17: val_loss did not improve from 0.15590\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.0997 - sparse_categorical_accuracy: 0.9638 - val_loss: 0.1634 - val_sparse_categorical_accuracy: 0.9531 - lr: 0.0010\n",
            "Epoch 18/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.0947 - sparse_categorical_accuracy: 0.9640\n",
            "Epoch 18: val_loss did not improve from 0.15590\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9638 - val_loss: 0.1678 - val_sparse_categorical_accuracy: 0.9531 - lr: 0.0010\n",
            "Epoch 19/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.0844 - sparse_categorical_accuracy: 0.9705\n",
            "Epoch 19: val_loss improved from 0.15590 to 0.14388, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9703 - val_loss: 0.1439 - val_sparse_categorical_accuracy: 0.9551 - lr: 8.0000e-04\n",
            "Epoch 20/60\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.0759 - sparse_categorical_accuracy: 0.9732\n",
            "Epoch 20: val_loss improved from 0.14388 to 0.14213, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9732 - val_loss: 0.1421 - val_sparse_categorical_accuracy: 0.9591 - lr: 8.0000e-04\n",
            "Epoch 21/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.9724\n",
            "Epoch 21: val_loss improved from 0.14213 to 0.14113, saving model to simpleCNN_weights.best.hdf5\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.0752 - sparse_categorical_accuracy: 0.9718 - val_loss: 0.1411 - val_sparse_categorical_accuracy: 0.9621 - lr: 8.0000e-04\n",
            "Epoch 22/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.0738 - sparse_categorical_accuracy: 0.9738\n",
            "Epoch 22: val_loss did not improve from 0.14113\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1527 - val_sparse_categorical_accuracy: 0.9511 - lr: 8.0000e-04\n",
            "Epoch 23/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.0656 - sparse_categorical_accuracy: 0.9781\n",
            "Epoch 23: val_loss did not improve from 0.14113\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.0658 - sparse_categorical_accuracy: 0.9779 - val_loss: 0.1501 - val_sparse_categorical_accuracy: 0.9611 - lr: 8.0000e-04\n",
            "Epoch 24/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.0642 - sparse_categorical_accuracy: 0.9788\n",
            "Epoch 24: val_loss did not improve from 0.14113\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.0630 - sparse_categorical_accuracy: 0.9793 - val_loss: 0.1454 - val_sparse_categorical_accuracy: 0.9621 - lr: 8.0000e-04\n",
            "Epoch 25/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.0591 - sparse_categorical_accuracy: 0.9787\n",
            "Epoch 25: val_loss did not improve from 0.14113\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.0579 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1607 - val_sparse_categorical_accuracy: 0.9601 - lr: 6.4000e-04\n",
            "Epoch 26/60\n",
            "145/154 [===========================>..] - ETA: 0s - loss: 0.0613 - sparse_categorical_accuracy: 0.9804\n",
            "Epoch 26: val_loss did not improve from 0.14113\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 0.0611 - sparse_categorical_accuracy: 0.9805 - val_loss: 0.1641 - val_sparse_categorical_accuracy: 0.9611 - lr: 6.4000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance\n",
        "Analyse the performance of the trained model, via the use of the training graphs and confusion matrix"
      ],
      "metadata": {
        "id": "A2VJwt0fqjfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10)) #Display losses and accuracy in a plot\n",
        "ax1.plot(history.history['loss'], label='Training')\n",
        "ax1.plot(history.history['val_loss'], label='Validation')\n",
        "ax1.legend()\n",
        "ax1.set_title('Loss')\n",
        "ax2.plot(history.history['sparse_categorical_accuracy'], label='Training')\n",
        "ax2.plot(history.history['val_sparse_categorical_accuracy'], label='Validation')\n",
        "ax2.legend()\n",
        "ax2.set_title('Accuracy')\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "try:\n",
        "  os.mkdir(\"/content/results\")  #Save figure as PNG, in order to save as metadata later\n",
        "  fig.savefig(\"/content/results/training_graph.png\")\n",
        "except:\n",
        "  print(\"Failed to save history figures\")\n",
        "\n",
        "print(\"Succesfully saved training graph\")"
      ],
      "metadata": {
        "id": "Jz0lRf4NbUcW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "34a16269-945f-432e-cf37-6365a66443ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfully saved training graph\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creation of the confusion matrix, based on the test split"
      ],
      "metadata": {
        "id": "7yjd_ptA0JBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_spectrogram = []\n",
        "test_labels = []\n",
        "\n",
        "for spectrogram, label in test_ds:  #Preload the test split\n",
        "  test_spectrogram.append(spectrogram.numpy())\n",
        "  test_labels.append(label.numpy())\n",
        "\n",
        "test_spectrogram = np.array(test_spectrogram)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "y_pred = np.argmax(model.predict(test_spectrogram), axis=1) #Make predictions of the test split\n",
        "y_true = test_labels\n",
        "print(\"Labels: \", test_labels.shape)\n",
        "\n",
        "test_acc = sum(y_pred == y_true) / len(y_true) #Calculate test split accuracy\n",
        "print(f'Test set accuracy: {test_acc:.0%}')\n",
        "\n",
        "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred) #Calculate confusion matrix based on predictions and true labels\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mtx,\n",
        "            xticklabels=commands,\n",
        "            yticklabels=commands,\n",
        "            annot=True, fmt='g')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Label')\n",
        "\n",
        "try:\n",
        "  plt.savefig(\"/content/results/confusion_matrix.png\") #Save confusion matrix as PNG\n",
        "except:\n",
        "  print(\"Failed to save confusion matrix\")\n",
        "\n",
        "print(\"Succesfully saved confusion matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2QzvGhmMfi9v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "outputId": "67027310-f9fe-4922-cbbb-7ee9031aae60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  (1003,)\n",
            "Test set accuracy: 96%\n",
            "Succesfully saved confusion matrix\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving trained model\n",
        "Saving the trained model to Google Drive, both in normal and TFLite versions."
      ],
      "metadata": {
        "id": "qo_RFIK1qvvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try: \n",
        "  drive.mount(\"/content/gdrive\", force_remount=False) #Check if Google Drive is still mounted\n",
        "  print(\"Google Drive succes!\")\n",
        "except:\n",
        "  print(\"Error\")\n",
        "\n",
        "modelName, tfLiteModel_name = get_model_name() #Get next available model name, and create the name based on parameters\n",
        "\n",
        "try:\n",
        "  if os.path.exists(modelSavePath) != True: os.makedirs(modelSavePath)\n",
        "  modelPath = \"/content/gdrive/MyDrive/Saved_models/\" + modelName\n",
        "  model.save(filepath=modelPath, overwrite=False, save_format='tf') #Save model as normal TF model\n",
        "except:\n",
        "  print(\"Error\")"
      ],
      "metadata": {
        "id": "n1Qp6M0vaqza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b103c969-8498-4268-b0c7-fa23b5205f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Google Drive succes!\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/Saved_models/V5.0_simpleCNN_MSWC_blue-red-unknown_spectrogram_05-04-2022/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert and save as TFlite version"
      ],
      "metadata": {
        "id": "HgKSaVf-0XWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(modelPath) # Path to the SavedModel directory\n",
        "tflite_model = converter.convert()  #Convert normal TF model to TF Lite version\n",
        "\n",
        "if os.path.exists(modelSavePath / \"tfLite_models/\") != True: os.makedirs(modelSavePath / \"tfLite_models/\") #Check if directory exists\n",
        "\n",
        "# Save the model.\n",
        "with open(tfLiteModel_name, 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "shutil.copyfile(tfLiteModel_name, (modelSavePath / \"tfLite_models\" / (tfLiteModel_name + \".tflite\"))) #Move to GoogleDrive"
      ],
      "metadata": {
        "id": "y2zv2cPUg6mO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5746ff5-7dac-4dc7-8782-18947fc078b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/gdrive/MyDrive/Saved_models/tfLite_models/V5.0_TFlite_simpleCNN_MSWC_blue-red-unknown_spectrogram_05-04-2022.tflite')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save meta data, containing the training graphs and confusion matrix to the model directory.\n",
        "\n",
        "Also adds a .CSV containing all the parameters that were used"
      ],
      "metadata": {
        "id": "BCIR9XFlz5D7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save model Meta Data\n",
        "#Comments from user to be saved in meta data\n",
        "userComments = \"Normal 1D spectrogram 129x124, from_logits=True in sparsecatagoricalAccuracy\"\n",
        "\n",
        "try:\n",
        "  metaDataPath = (modelPath + \"/metadata\") #Move result pictures to the corresponding model in GoogleDrive\n",
        "  os.mkdir(metaDataPath)\n",
        "  shutil.move(\"/content/results/training_graph.png\", (metaDataPath + \"/training_graph.png\"))\n",
        "  shutil.move(\"/content/results/confusion_matrix.png\", (metaDataPath + \"/confusion_matrix.png\"))\n",
        "except:\n",
        "  print(\"Could not create metadata directory in saved model\")\n",
        "\n",
        "if data_augmentation_bool != True: \n",
        "  augmentation_chance = 0 \n",
        "  shift_percentage = 0 #Set chances to 0 if augmentation is not performed\n",
        "  noise_percentage = 0 \n",
        "\n",
        "headerMeta = [\"ModelName\", \"Test split accuracy\" , \"CNN\", \"Dataset\", \"TF_Version\", \"Data augmentation percentage\", \"Time shift percentage\", \"Noise addition percentage\",\n",
        "              \"Noise SNR\", \"Normalize Spectrogram\", \"Sample Rate\", \"Window length(Spectro)\", \"Hop length(Spectro)\", \"NFFT size\", \"Epochs\", \n",
        "              \"Batch size\", \"Comments\"]\n",
        "\n",
        "dataRowMeta = [modelName, test_acc, modelType, datasetType, str(tf. __version__), augmentation_chance, shift_percentage, noise_percentage,\n",
        "           desired_snr, str(normalize_spectrogram_bool), sampleRate, sampleSegment, sampleHop, nfftSize, EPOCHS,\n",
        "           batch_size, userComments]\n",
        "\n",
        "with open((metaDataPath + \"/metadata.csv\"), 'w', encoding='UTF8') as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow(headerMeta) #Save metadata as CSV in corresponding model\n",
        "  writer.writerow(dataRowMeta)\n",
        "print(\"Succesfully saved metadata CSV\")"
      ],
      "metadata": {
        "id": "GB3sue6z-zvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d224319-c877-43c5-f9b7-19310bbeaa42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfully saved metadata CSV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing model with custom dataset"
      ],
      "metadata": {
        "id": "w8dXE2PZC_M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try: \n",
        "  drive.mount(\"/content/gdrive\", force_remount=False) #Check if Google Drive is still mounted\n",
        "  print(\"Google Drive succes!\")\n",
        "except:\n",
        "  print(\"Error\")\n",
        "\n",
        "if os.path.exists(custom_dataset_path) != True: \n",
        "  print(\"Error, dataset path does not exist\")\n",
        "  sys.exit()\n",
        "if 'model' in locals(): #Checks if a model was already trained this session, otherwise allows for the selection of a pretrained model located in the Google Drive\n",
        "  print(\"Model already loaded, continueing\")\n",
        "else:\n",
        "  print(\"Model not yet loaded, input model string to load:\")\n",
        "  print(os.listdir(modelSavePath))\n",
        "  model_to_load = input(\"Model to load: \") #User input of the model to be loaded\n",
        "  model = tf.keras.models.load_model(str(modelSavePath / model_to_load))\n",
        "  commands = get_commands(datasetPath) #Gets the available commands, as they were not yet loaded\n",
        "\n",
        "all_custom_paths = tf.io.gfile.glob(str(custom_dataset_path / \"*\")) #Loads all the files in the custom dataset folder\n",
        "total_amount_frames = 0\n",
        "total_amount_wrong_predictions = 0\n",
        "time_interference_array = []\n",
        "time_processing_array = []\n",
        "\n",
        "for index, path_custom in enumerate(all_custom_paths):\n",
        "  wrong_predictions_time = [\"Time of detected command(seconds): \"]\n",
        "  wrong_predictions_label = [\"Detected command: \"]\n",
        "\n",
        "  encoded_custom = tf.io.read_file(path_custom) #Read file and decode\n",
        "  custom_audio, _ = tf.audio.decode_wav(contents=encoded_custom)\n",
        "  custom_audio, _ = tf.unstack(custom_audio, axis=-1) #Remove stereo channel, make mono\n",
        "  custom_frames = tf.signal.frame(custom_audio, 16000, 8000, pad_end=True) #Chop the file into 1 second segments, uses an hopLength of 0.5s\n",
        "  total_amount_frames = total_amount_frames + custom_frames.shape[0] #Saves the amount of frames for the accuracy calculation\n",
        "\n",
        "  for frame_number, frame in enumerate(custom_frames):\n",
        "    start = time.perf_counter()\n",
        "    custom_spectrogram = get_spectrogram(frame) #Convert audio to a spectrogram\n",
        "    custom_spectrogram = tf.expand_dims(custom_spectrogram, axis=0) #Add another dimension as this is expected by the model\n",
        "    time_processing_array.append(time.perf_counter() - start) #Saves the time that was needed for preprocessing to a spectrogram\n",
        "\n",
        "    start = time.perf_counter()\n",
        "    predicted_label = np.argmax(model(custom_spectrogram), axis=1) #Perform inference and save the predicted label\n",
        "    time_interference_array.append(time.perf_counter() - start) #Saves the time needed for inference\n",
        "\n",
        "    if predicted_label != 2: #Checks if the predicted label is not \"unknown\"\n",
        "      seconds = get_seconds(frame_number) #Gets the location in seconds where the prediction occured\n",
        "      wrong_predictions_time.append(seconds)  #Save the time and predicted command\n",
        "      wrong_predictions_label.append(commands[predicted_label.item()])\n",
        "      total_amount_wrong_predictions += 1 #Keep track of the amount of wrong predictions\n",
        "\n",
        "  print(\"file being read: \", path_custom)\n",
        "  file_name_entire = path_custom.split(\"/\")\n",
        "  file_name_entire = file_name_entire[-1].split(\".\")\n",
        "  shortened_file_name = file_name_entire[0].split(\"__\")[0] #Gets a shortened filename of the .WAV\n",
        "\n",
        "  if \"modelName\" in locals(): #Checks if a modelName is already present in the loaded variables\n",
        "    if os.path.exists(modelPath + \"/custom_dataset_results\") != True: \n",
        "      os.mkdir((modelPath + \"/custom_dataset_results\"))\n",
        "    file_name = modelPath + \"/custom_dataset_results/\" + shortened_file_name + \"_\" + modelName + \".csv\" #Set the filename of the .CSV\n",
        "  else:\n",
        "    if os.path.exists(str(modelSavePath / model_to_load / \"custom_dataset_results\")) != True:\n",
        "      os.mkdir(str(modelSavePath / model_to_load / \"custom_dataset_results\"))\n",
        "    file_name = str(modelSavePath / model_to_load / \"custom_dataset_results\") + \"/\" + shortened_file_name + \"_\" + model_to_load + \".csv\"\n",
        "\n",
        "  wrong_predictions = np.array([wrong_predictions_time, wrong_predictions_label])\n",
        "  wrong_predictions.transpose()\n",
        "  np.savetxt(file_name, wrong_predictions, delimiter=\",\", fmt=\"%s\") #Save the results into a .CSV and store it inside of the model that was used\n",
        "  print(\"Done predicting file, results saved in model folder\")\n",
        "\n",
        "print()\n",
        "print()\n",
        "print(\"Done with custom dataset predictions\")\n",
        "accuracy_custom_test = 100 - ((total_amount_wrong_predictions / total_amount_frames) * 100) #Accuracy calculation\n",
        "print(\"Accuracy on the test set: \", \"%.2f\" % accuracy_custom_test, \"%\")\n",
        "print(\"Amount of wrong predictions:\", total_amount_wrong_predictions)\n",
        "\n",
        "print()\n",
        "print('Average interference time in milliseconds.', tf.reduce_mean(time_interference_array).numpy()*1000) #Show the average time, says little about the actual performance on the Raspberry Pi\n",
        "print('Average processing time in milliseconds.', tf.reduce_mean(time_processing_array).numpy()*1000)\n",
        "print(\"Average total time.\", (tf.reduce_mean(time_interference_array).numpy()*1000) + (tf.reduce_mean(time_processing_array).numpy()*1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F25Y0bN3C-g4",
        "outputId": "5c45e011-f5b6-45a3-8b8b-baf08377bd06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Google Drive succes!\n",
            "Model already loaded, continueing\n",
            "file being read:  /content/gdrive/MyDrive/Datasets/Real-life_Verification/MTest3__commands+noise_noGain_quick.wav\n",
            "Done predicting file, results saved in model folder\n",
            "file being read:  /content/gdrive/MyDrive/Datasets/Real-life_Verification/MTest2__commands+noise_equalSNR_slow.wav\n",
            "Done predicting file, results saved in model folder\n",
            "file being read:  /content/gdrive/MyDrive/Datasets/Real-life_Verification/Mtest1__commands+noise_equalSNR_quick.wav\n",
            "Done predicting file, results saved in model folder\n",
            "file being read:  /content/gdrive/MyDrive/Datasets/Real-life_Verification/MTest6__commands+noise_5SNR_slow.wav\n",
            "Done predicting file, results saved in model folder\n",
            "file being read:  /content/gdrive/MyDrive/Datasets/Real-life_Verification/MTest5__commands+noise_5SNR_quick.wav\n",
            "Done predicting file, results saved in model folder\n",
            "file being read:  /content/gdrive/MyDrive/Datasets/Real-life_Verification/MTest4__commands+noise_noGain_slow.wav\n",
            "Done predicting file, results saved in model folder\n",
            "file being read:  /content/gdrive/MyDrive/Datasets/Real-life_Verification/MTestOG2__blue_red_lavalier_slow.wav\n",
            "Done predicting file, results saved in model folder\n",
            "file being read:  /content/gdrive/MyDrive/Datasets/Real-life_Verification/MTestOG1__blue_red_lavalier_quick.wav\n",
            "Done predicting file, results saved in model folder\n",
            "\n",
            "\n",
            "Done with custom dataset predictions\n",
            "Accuracy on the test set:  69.50 %\n",
            "Amount of wrong predictions: 276\n",
            "\n",
            "Average interference time in milliseconds. 5.085092969238758\n",
            "Average processing time in milliseconds. 2.3517943918704987\n",
            "Average total time. 7.436887361109257\n"
          ]
        }
      ]
    }
  ]
}